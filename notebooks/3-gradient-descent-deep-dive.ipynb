{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent in depth\n",
    "=========================\n",
    "\n",
    "*Fraida Fund*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# for 3d interactive plots\n",
    "from ipywidgets import interact, fixed\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generated by a linear function\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear_regression_data(n=100, d=1, coef=[5], intercept=1, sigma=0):\n",
    "  x = np.random.randn(n,d)\n",
    "  y = (np.dot(x, coef) + intercept).squeeze() + sigma * np.random.randn(n)\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent for simple linear regression\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = np.array([2, 3])\n",
    "# y = 2 + 3x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = w_true[0]\n",
    "coef = w_true[1:]\n",
    "print(intercept, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_linear_regression_data(n=n_samples, d=1, coef=coef, intercept=intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones((n_samples, 1)), x))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a descent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each gradient descent step, we will compute\n",
    "\n",
    "$$ \n",
    "w^{t+1} = w^t - \\alpha^t \\nabla L(w^t)  \n",
    "$$\n",
    "\n",
    "With a mean squared error loss function\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "L(w) &= \\frac{1}{2} \\sum_{i=1}^n (y_i - \\langle w,x_i \\rangle)^2 \\\\\n",
    "     &= \\frac{1}{2} \\|y - Xw\\|^2 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "we will compute the weights at each step as\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "w^{t+1} &= w^t + \\alpha^t \\sum_{i=1}^n (y_i - \\langle w^t,x_i \\rangle) x_i \\\\\n",
    "        &= w^t + \\alpha^t X^T (y - X w^t)                  \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_step(w, X, y, lr):\n",
    "  # use current parameters to get y_hat\n",
    "  y_hat = np.dot(X,w)\n",
    "  # compute gradient for this y_hat\n",
    "  grad = np.matmul(X.T, y_hat-y)\n",
    "  # update weights\n",
    "  w_new = w - lr*grad\n",
    "\n",
    "  # we don't have to actually compute MSE\n",
    "  # but I want to, for visualization \n",
    "  mse = 1.0/len(y)*np.sum((y_hat - y)**2)\n",
    "\n",
    "  return (w_new, mse, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "lr = 0.001\n",
    "w_init = np.random.randn(len(w_true))\n",
    "print(w_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_steps = np.zeros((itr, len(w_init)))\n",
    "mse_steps = np.zeros(itr)\n",
    "grad_steps = np.zeros((itr, len(w_init)))\n",
    "\n",
    "w_star = w_init\n",
    "for i in range(itr):\n",
    "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
    "  w_steps[i] = w_star\n",
    "  mse_steps[i] = mse\n",
    "  grad_steps[i] = gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(w_true))\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,3,1);\n",
    "\n",
    "for n in range(len(w_true)):\n",
    "  plt.axhline(y=w_true[n], linestyle='--', color=colors[n]);\n",
    "  sns.lineplot(np.arange(itr), w_steps[:,n], color=colors[n]);\n",
    "\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Coefficient Value\");\n",
    "\n",
    "plt.subplot(1,3, 2);\n",
    "sns.lineplot(np.arange(itr), mse_steps);\n",
    "#plt.yscale(\"log\")\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Mean Squared Error\");\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3);\n",
    "for n in range(len(coef)+1):\n",
    "  sns.lineplot(np.arange(itr), grad_steps[:,n], color=colors[n]);\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Gradient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things to try\n",
    "\n",
    "-   What happens if we increase the learning rate?\n",
    "-   What happens if we decrease the learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descent path\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "\n",
    "We will revisit our multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = [2, 6, 5]\n",
    "intercept = w_true[0]\n",
    "coef = w_true[1:]\n",
    "print(intercept, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_linear_regression_data(n=n_samples, d=2, coef=coef, intercept=intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.arange(2, 8, 0.05)\n",
    "mses_coefs = np.zeros((len(coefs), len(coefs)))\n",
    "\n",
    "for idx_1, c_1 in enumerate(coefs):\n",
    "  for idx_2, c_2 in enumerate(coefs):\n",
    "    y_hat_c = (intercept + np.dot(x,[c_1, c_2])).squeeze()\n",
    "    mses_coefs[idx_1,idx_2] =  1.0/(len(y_hat_c)) * np.sum((y - y_hat_c)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs)\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((np.ones((n_samples, 1)), x))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "lr = 0.001\n",
    "w_init = [intercept, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_steps = np.zeros((itr, len(w_init)))\n",
    "mse_steps = np.zeros(itr)\n",
    "grad_steps = np.zeros((itr, len(w_init)))\n",
    "\n",
    "w_star = w_init\n",
    "for i in range(itr):\n",
    "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
    "  w_steps[i] = w_star\n",
    "  mse_steps[i] = mse\n",
    "  grad_steps[i] = gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(w_true))\n",
    "\n",
    "for n in range(len(w_true)):\n",
    "  plt.axhline(y=w_true[n], linestyle='--', color=colors[n]);\n",
    "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n]);\n",
    "\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Coefficient Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs);\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');\n",
    "sns.lineplot(x=w_steps[:,2], y=w_steps[:,1], color='black', sort=False, alpha=0.5);\n",
    "sns.scatterplot(x=w_steps[:,2], y=w_steps[:,1], hue=np.arange(itr), edgecolor=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things to try\n",
    "\n",
    "-   What happens if we generate noisy data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent\n",
    "---------------------------\n",
    "\n",
    "For stochastic gradient descent, we will compute the gradient and update\n",
    "the weights using one sample (or a mini-batch of samples) in each step.\n",
    "\n",
    "**A note on sampling**: In practice, the samples are often sampled\n",
    "without replacement, but the statistical guarantee of convergence is for\n",
    "sampling with replacement. In this example, we sample with replacement.\n",
    "You can read more about different varieties of gradient descent and\n",
    "stochastic gradient descent in [How is stochastic gradient descent\n",
    "implemented in the context of machine learning and deep\n",
    "learning](https://sebastianraschka.com/faq/docs/sgd-methods.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_step(w, X, y, lr, n):\n",
    "\n",
    "  idx_sample = np.random.choice(X.shape[0], n, replace=True)\n",
    "\n",
    "  X_sample = X[idx_sample, :]\n",
    "  y_sample = y[idx_sample]\n",
    "\n",
    "  # use current parameters to get y_hat\n",
    "  y_hat = np.dot(X_sample,w)\n",
    "  # compute gradient for this y_hat\n",
    "  grad = np.matmul(X_sample.T, y_hat-y_sample)\n",
    "  # update weights\n",
    "  w_new = w - lr*grad\n",
    "\n",
    "  # we don't have to actually compute MSE\n",
    "  # but I want to, for visualization \n",
    "  mse = 1.0/len(y)*np.sum((y-np.dot(X, w))**2)\n",
    "\n",
    "  return (w_new, mse, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "lr = 0.05\n",
    "n = 1\n",
    "w_init = [intercept, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_steps = np.zeros((itr, len(w_init)))\n",
    "mse_steps = np.zeros(itr)\n",
    "\n",
    "w_star = w_init\n",
    "for i in range(itr):\n",
    "  w_star, mse, grad = sgd_step(w_star, X, y, lr, n)\n",
    "  w_steps[i] = w_star\n",
    "  mse_steps[i] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(coef) + 1)\n",
    "\n",
    "plt.axhline(y=intercept, linestyle='--', color=colors[0]);\n",
    "sns.lineplot(x=np.arange(itr), y=w_steps[:,0], color=colors[0]);\n",
    "\n",
    "for n in range(len(coef)):\n",
    "  plt.axhline(y=coef[n], linestyle='--', color=colors[n+1]);\n",
    "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n+1], color=colors[n+1]);\n",
    "\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Coefficient Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs);\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');\n",
    "sns.lineplot(x=w_steps[:,2], y=w_steps[:,1], color='black', sort=False, alpha=0.5);\n",
    "sns.scatterplot(x=w_steps[:,2], y=w_steps[:,1], hue=np.arange(itr), edgecolor=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things to try\n",
    "\n",
    "-   Increase learning rate?\n",
    "-   Decrease learning rate?\n",
    "-   Use decaying learning rate $\\alpha^t = \\frac{C}{t}$?\n",
    "-   Increase number of samples used in each iteration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent with noise\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "\n",
    "This time, we will use the `sigma` argument in our\n",
    "`generate_linear_regression_data` function to generate data that does\n",
    "not perfectly fit a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = [2, 6, 5]\n",
    "intercept = w_true[0]\n",
    "coef = w_true[1:]\n",
    "print(intercept, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_linear_regression_data(n=n_samples, d=2, coef=coef, intercept=intercept, sigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.arange(2, 8, 0.05)\n",
    "mses_coefs = np.zeros((len(coefs), len(coefs)))\n",
    "\n",
    "for idx_1, c_1 in enumerate(coefs):\n",
    "  for idx_2, c_2 in enumerate(coefs):\n",
    "    y_hat_c = (intercept + np.dot(x,[c_1, c_2])).squeeze()\n",
    "    mses_coefs[idx_1,idx_2] =  1.0/(len(y_hat_c)) * np.sum((y - y_hat_c)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs)\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform gradient descent\n",
    "\n",
    "This time, the gradient descent may not necessarily arrive at the “true”\n",
    "coefficient values. That’s not because it does not find the coefficients\n",
    "with minimum MSE; it’s because the coefficients with minimum MSE on the\n",
    "noisy training data are not necessarily the “true” coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((np.ones((n_samples, 1)), x))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "lr = 0.0002\n",
    "w_init = [intercept, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_steps = np.zeros((itr, len(w_init)))\n",
    "mse_steps = np.zeros(itr)\n",
    "\n",
    "w_star = w_init\n",
    "for i in range(itr):\n",
    "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
    "  w_steps[i] = w_star\n",
    "  mse_steps[i] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(w_true))\n",
    "\n",
    "for n in range(len(w_true)):\n",
    "  plt.axhline(y=w_true[n], linestyle='--', color=colors[n]);\n",
    "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n]);\n",
    "\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Coefficient Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs);\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');\n",
    "sns.lineplot(x=w_steps[:,2], y=w_steps[:,1], color='black', sort=False, alpha=0.5);\n",
    "sns.scatterplot(x=w_steps[:,2], y=w_steps[:,1], hue=np.arange(itr), edgecolor=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D(elev=20, azim=-20, X1=X1, X2=X2, mses_coefs=mses_coefs, \n",
    "            w_steps=w_steps, mse_steps=mse_steps):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot(projection='3d')\n",
    "\n",
    "\n",
    "    # Plot the surface.\n",
    "    ax.plot_surface(X1, X2, mses_coefs, alpha=0.5, cmap=cm.coolwarm,\n",
    "                          linewidth=0, antialiased=False)\n",
    "    ax.scatter3D(w_steps[:, 2], w_steps[:, 1], mse_steps, s=5, color='black')\n",
    "    ax.plot(w_steps[:, 2], w_steps[:, 1], mse_steps, color='gray')\n",
    "\n",
    "\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('w2')\n",
    "    ax.set_ylabel('w1')\n",
    "    ax.set_zlabel('MSE')\n",
    "\n",
    "interact(plot_3D, elev=np.arange(-90,90,10), azim=np.arange(-90,90,10),\n",
    "         X1=fixed(X1), X2=fixed(X2), mses_coefs=fixed(mses_coefs),\n",
    "         w_steps=fixed(w_steps), mse_steps=fixed(mse_steps));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform stochastic gradient descent\n",
    "\n",
    "With data that does not perfectly fit the linear model, the stochastic\n",
    "gradient descent converges to a “noise ball” around the optimal\n",
    "solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 200\n",
    "lr = 0.05\n",
    "w_init = [intercept, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_steps = np.zeros((itr, len(w_init)))\n",
    "mse_steps = np.zeros(itr)\n",
    "\n",
    "w_star = w_init\n",
    "for i in range(itr):\n",
    "  w_star, mse, grad = sgd_step(w_star, X, y, lr, n) \n",
    "  w_steps[i] = w_star\n",
    "  mse_steps[i] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(w_true))\n",
    "\n",
    "for n in range(len(w_true)):\n",
    "  plt.axhline(y=w_true[n], linestyle='--', color=colors[n]);\n",
    "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n]);\n",
    "\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Coefficient Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs);\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=5);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');\n",
    "sns.lineplot(x=w_steps[:,2], y=w_steps[:,1], color='black', sort=False, alpha=0.5);\n",
    "sns.scatterplot(x=w_steps[:,2], y=w_steps[:,1], hue=np.arange(itr), edgecolor=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D(elev=20, azim=-20, X1=X1, X2=X2, mses_coefs=mses_coefs, \n",
    "            w_steps=w_steps, mse_steps=mse_steps):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot(projection='3d')\n",
    "\n",
    "\n",
    "    # Plot the surface.\n",
    "    ax.plot_surface(X1, X2, mses_coefs, alpha=0.5, cmap=cm.coolwarm,\n",
    "                          linewidth=0, antialiased=False)\n",
    "    ax.scatter3D(w_steps[:, 2], w_steps[:, 1], mse_steps, s=5, color='black')\n",
    "    ax.plot(w_steps[:, 2], w_steps[:, 1], mse_steps, color='gray')\n",
    "\n",
    "\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('w2')\n",
    "    ax.set_ylabel('w1')\n",
    "    ax.set_zlabel('MSE')\n",
    "\n",
    "interact(plot_3D, elev=np.arange(-90,90,10), azim=np.arange(-90,90,10),\n",
    "         X1=fixed(X1), X2=fixed(X2), mses_coefs=fixed(mses_coefs),\n",
    "         w_steps=fixed(w_steps), mse_steps=fixed(mse_steps));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A less friendly loss surface\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true = [2, 5, 5]\n",
    "intercept = w_true[0]\n",
    "coef = w_true[1:]\n",
    "print(intercept, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "d = 1\n",
    "sigma = 1\n",
    "\n",
    "x1 = np.random.randn(n_samples,d)\n",
    "x2 = x1 + (sigma/5)*np.random.randn(n_samples,1)\n",
    "x = np.column_stack([x1, x2])\n",
    "y = (np.dot(x, coef) + intercept).squeeze() + sigma * np.random.randn(n_samples)\n",
    "\n",
    "\n",
    "X = np.column_stack((np.ones((n_samples, 1)), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(x=x1.squeeze(), y=x2.squeeze())\n",
    "_ = plt.xlabel('x1')\n",
    "_ = plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.arange(3, 7, 0.02)\n",
    "mses_coefs = np.zeros((len(coefs), len(coefs)))\n",
    "\n",
    "for idx_1, c_1 in enumerate(coefs):\n",
    "  for idx_2, c_2 in enumerate(coefs):\n",
    "    y_hat_c = (intercept + np.dot(x,[c_1, c_2])).squeeze()\n",
    "    mses_coefs[idx_1,idx_2] =  1.0/(len(y_hat_c)) * np.sum((y - y_hat_c)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs)\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=15);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "lr = 0.002\n",
    "n = 1\n",
    "w_init = [intercept, 3, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_steps = np.zeros((itr, len(w_init)))\n",
    "mse_steps = np.zeros(itr)\n",
    "grad_steps = np.zeros((itr, len(w_init)))\n",
    "\n",
    "w_star = w_init\n",
    "for i in range(itr):\n",
    "  w_star, mse, gradient = gd_step(w_star, X, y, lr)\n",
    "  w_steps[i] = w_star\n",
    "  mse_steps[i] = mse\n",
    "  grad_steps[i] = gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(w_true))\n",
    "\n",
    "for n in range(len(w_true)):\n",
    "  plt.axhline(y=w_true[n], linestyle='--', color=colors[n]);\n",
    "  sns.lineplot(x=np.arange(itr), y=w_steps[:,n], color=colors[n]);\n",
    "\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.ylabel(\"Coefficient Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5));\n",
    "X1, X2 = np.meshgrid(coefs, coefs);\n",
    "p = plt.contour(X1, X2, mses_coefs, levels=10);\n",
    "plt.clabel(p, inline=1, fontsize=10);\n",
    "plt.xlabel('w2');\n",
    "plt.ylabel('w1');\n",
    "sns.lineplot(x=w_steps[:,2], y=w_steps[:,1], color='black', alpha=0.5, sort=False);\n",
    "sns.scatterplot(x=w_steps[:,2], y=w_steps[:,1], hue=np.arange(itr), edgecolor=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D(elev=20, azim=-20, X1=X1, X2=X2, mses_coefs=mses_coefs, \n",
    "            w_steps=w_steps, mse_steps=mse_steps):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot(projection='3d')\n",
    "\n",
    "\n",
    "    # Plot the surface.\n",
    "    ax.plot_surface(X1, X2, mses_coefs, alpha=0.5, cmap=cm.coolwarm,\n",
    "                          linewidth=0, antialiased=False)\n",
    "    ax.scatter3D(w_steps[:, 2], w_steps[:, 1], mse_steps, s=50, color='black')\n",
    "    ax.plot(w_steps[:, 2], w_steps[:, 1], mse_steps, color='gray')\n",
    "\n",
    "\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('w2')\n",
    "    ax.set_ylabel('w1')\n",
    "    ax.set_zlabel('MSE')\n",
    "\n",
    "interact(plot_3D, elev=np.arange(-90,90,10), azim=np.arange(-90,90,10),\n",
    "         X1=fixed(X1), X2=fixed(X2), mses_coefs=fixed(mses_coefs),\n",
    "         w_steps=fixed(w_steps), mse_steps=fixed(mse_steps));"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
