{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression metrics\n",
    "------------------\n",
    "\n",
    "In this notebook, we will explore some metrics typically applied to\n",
    "linear regression models:\n",
    "\n",
    "-   R2\n",
    "-   Mean squared error (RSS divided by number of samples)\n",
    "-   Ratio of RSS for regression model to sample variance (“RSS for\n",
    "    prediction by mean”)\n",
    "\n",
    "using some synthetic data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synthetic data\n",
    "-----------------------\n",
    "\n",
    "We will generate four sets of synthetic data for a simple linear\n",
    "regression.\n",
    "\n",
    "Each dataset will be generated using the `make_regression` function in\n",
    "`sklearn`’s `datasets` module. This will:\n",
    "\n",
    "-   generate a random regression coefficient, $w_1$,\n",
    "-   generate `n_samples` points on the line defined by that coefficient\n",
    "    (i.e. generate random $x$ and then compute $y$ using the equation\n",
    "    for the linear model),\n",
    "-   and then add Gaussian noise with standard deviation defined by the\n",
    "    `noise` argument to each of the `n_samples` points.\n",
    "\n",
    "We will also scale all the “features” to the $[-1, 1]$ range using\n",
    "`sklearn`’s `MaxAbsScaler`, so that we can make reasonable comparisons\n",
    "between the datasets.\n",
    "\n",
    "The sets `hivar1` and `lovar1` will be identical to one another with\n",
    "respect to the number of samples and regression coefficents, but the\n",
    "`hivar1` set will have 5x the noise of the `lovar1` set.\n",
    "\n",
    "Similarly, the sets `hivar2` and `lovar2` will be identical to one\n",
    "another with respect to the number of samples and regression\n",
    "coefficents, but the `hivar2` set will have 5 times the noise of the\n",
    "`lovar2` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hivar1, y_hivar1 = datasets.make_regression(n_samples=300, n_features=1, noise=20, random_state=4)\n",
    "X_hivar1 = preprocessing.MaxAbsScaler().fit_transform(X_hivar1)\n",
    "\n",
    "X_lovar1, y_lovar1 = datasets.make_regression(n_samples=300, n_features=1, noise=4, random_state=4)\n",
    "X_lovar1 = preprocessing.MaxAbsScaler().fit_transform(X_lovar1)\n",
    "\n",
    "X_hivar2, y_hivar2 = datasets.make_regression(n_samples=150, n_features=1, noise=50, random_state=9)\n",
    "X_hivar2 = preprocessing.MaxAbsScaler().fit_transform(X_hivar2)\n",
    "\n",
    "X_lovar2, y_lovar2 = datasets.make_regression(n_samples=150, n_features=1, noise=10, random_state=9)\n",
    "X_lovar2 = preprocessing.MaxAbsScaler().fit_transform(X_lovar2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a linear regression\n",
    "\n",
    "Next, we will fit a linear regression to each data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_hivar1 = LinearRegression().fit(X_hivar1, y_hivar1)\n",
    "regr_lovar1 = LinearRegression().fit(X_lovar1, y_lovar1)\n",
    "regr_hivar2 = LinearRegression().fit(X_hivar2, y_hivar2)\n",
    "regr_lovar2 = LinearRegression().fit(X_lovar2, y_lovar2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data and regression line\n",
    "\n",
    "Finally, for each dataset:\n",
    "\n",
    "-   we plot the data points and the fitted linear regression line\n",
    "-   we print the coefficient $w_1$ on each plot\n",
    "-   we print the R2 value on each plot\n",
    "-   we compute the MSE of the regression, and print it on each plot\n",
    "-   we compute the “MSE of prediction by mean”, and print it on each\n",
    "    plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 8)\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "sns.scatterplot(x=X_hivar1.squeeze(), y=y_hivar1, ax=ax1);\n",
    "sns.lineplot(x=X_hivar1.squeeze(), y=regr_hivar1.predict(X_hivar1), color='red', ax=ax1);\n",
    "sns.lineplot(x=X_hivar1.squeeze(), y=np.mean(y_hivar1), color='purple', ax=ax1);\n",
    "ax1.title.set_text('w1: %s, R2 score: %s \\n MSE regression: %s \\n MSE mean: %s' % \n",
    "          (\n",
    "           '{0:.2f}'.format(regr_hivar1.coef_[0]),\n",
    "           '{0:.4f}'.format(metrics.r2_score(y_hivar1, regr_hivar1.predict(X_hivar1))),\n",
    "           '{0:.4f}'.format(np.mean((regr_hivar1.predict(X_hivar1)-y_hivar1)**2)),\n",
    "           '{0:.4f}'.format(np.mean(( np.mean(y_hivar1)-y_hivar1)**2))\n",
    "          ));\n",
    "ax1.text(0.75, -250, \"(1)\", size='medium', color='black', weight='semibold');\n",
    "ax1.set_ylim(-300, 300);\n",
    "ax1.set_xlim(-1, 1);\n",
    "\n",
    "sns.scatterplot(x=X_lovar1.squeeze(), y=y_lovar1, ax=ax2);\n",
    "sns.lineplot(x=X_lovar1.squeeze(), y=regr_lovar1.predict(X_lovar1), color='red', ax=ax2);\n",
    "sns.lineplot(x=X_lovar1.squeeze(), y=np.mean(y_lovar1), color='purple', ax=ax2);\n",
    "ax2.title.set_text('w1: %s, R2 score: %s \\n MSE regression: %s \\n MSE mean: %s' % \n",
    "          (\n",
    "           '{0:.2f}'.format(regr_lovar1.coef_[0]),\n",
    "           '{0:.4f}'.format(metrics.r2_score(y_lovar1, regr_lovar1.predict(X_lovar1))),\n",
    "           '{0:.4f}'.format(np.mean((regr_lovar1.predict(X_lovar1)-y_lovar1)**2)),\n",
    "           '{0:.4f}'.format(np.mean(( np.mean(y_lovar1)-y_lovar1)**2))\n",
    "          ));\n",
    "ax2.text(0.75, -250, \"(2)\", size='medium', color='black', weight='semibold');\n",
    "ax2.set_ylim(-300, 300);\n",
    "ax2.set_xlim(-1, 1);\n",
    "\n",
    "sns.scatterplot(x=X_hivar2.squeeze(), y=y_hivar2, ax=ax3);\n",
    "sns.lineplot(x=X_hivar2.squeeze(), y=regr_hivar2.predict(X_hivar2), color='red', ax=ax3);\n",
    "sns.lineplot(x=X_hivar2.squeeze(), y=np.mean(y_hivar2), color='purple', ax=ax3);\n",
    "ax3.title.set_text('w1: %s, R2 score: %s \\n MSE regression: %s \\n MSE mean: %s' % \n",
    "          (\n",
    "           '{0:.2f}'.format(regr_hivar2.coef_[0]),\n",
    "           '{0:.4f}'.format(metrics.r2_score(y_hivar2, regr_hivar2.predict(X_hivar2))),\n",
    "           '{0:.4f}'.format(np.mean((regr_hivar2.predict(X_hivar2)-y_hivar2)**2)),\n",
    "           '{0:.4f}'.format(np.mean(( np.mean(y_hivar2)-y_hivar2)**2))\n",
    "          ));\n",
    "ax3.text(0.75, -250, \"(3)\", size='medium', color='black', weight='semibold');\n",
    "ax3.set_ylim(-300, 300);\n",
    "ax3.set_xlim(-1, 1);\n",
    "\n",
    "sns.scatterplot(x=X_lovar2.squeeze(), y=y_lovar2, ax=ax4);\n",
    "sns.lineplot(x=X_lovar2.squeeze(), y=regr_lovar2.predict(X_lovar2), color='red', ax=ax4);\n",
    "sns.lineplot(x=X_lovar2.squeeze(), y=np.mean(y_lovar2), color='purple', ax=ax4);\n",
    "ax4.title.set_text('w1: %s, R2 score: %s \\n MSE regression: %s \\n MSE mean: %s' % \n",
    "          (\n",
    "           '{0:.2f}'.format(regr_lovar2.coef_[0]),\n",
    "           '{0:.4f}'.format(metrics.r2_score(y_lovar2, regr_lovar2.predict(X_lovar2))),\n",
    "           '{0:.4f}'.format(np.mean((regr_lovar2.predict(X_lovar2)-y_lovar2)**2)),\n",
    "           '{0:.4f}'.format(np.mean(( np.mean(y_lovar2)-y_lovar2)**2))\n",
    "          ));\n",
    "ax4.text(0.75, -250, \"(4)\", size='medium', color='black', weight='semibold');\n",
    "ax4.set_ylim(-300, 300);\n",
    "ax4.set_xlim(-1, 1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret results\n",
    "-----------------\n",
    "\n",
    "Based on the figures above, we can make the following statements:\n",
    "\n",
    "From $w_1$, and visually from the slope of the regression line:\n",
    "\n",
    "-   For **(1)**, **(2)**: an increase in $x$ of 1 is, on average,\n",
    "    associated with an increase in $y$ of about 100.\n",
    "-   For **(3)**, **(4)**: an increase in $x$ of 1 is, on average,\n",
    "    associated with an increase in $y$ of about 240.\n",
    "\n",
    "From the R2 score, and visually from the variance around the regression\n",
    "line:\n",
    "\n",
    "-   For **(1)**, **(3)**: about 75% of the variance in $y$ is explained\n",
    "    by the regression on $x$.\n",
    "-   For **(2)**, **(4)**: about 99% of the variance in $y$ is explained\n",
    "    by the regression on $x$.\n",
    "\n",
    "We also observe:\n",
    "\n",
    "-   The MSE of the regression line is equivalent to the variance of the\n",
    "    noise we added around the regression line. (Take the square of the\n",
    "    `noise` argument we used, which was the standard deviation of the\n",
    "    noise.)\n",
    "-   The greater the slope of the regression line, the more error is\n",
    "    associated with prediction by mean. Prediction by mean is the same\n",
    "    thing as prediction by a line with intercept $w_0 = \\overline{y}$\n",
    "    and slope $w_1 = 0$ (purple line in the figures above). The greater\n",
    "    the true $w_1$, the more “wrong” the $w_1 = 0$ prediction is.\n",
    "-   The ratio of MSE of the regression line to MSE of prediction by\n",
    "    mean, is $1-R2$."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
